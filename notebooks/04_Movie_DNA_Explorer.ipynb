{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b07cb3",
   "metadata": {},
   "source": [
    "# Project 3: The \"Movie DNA\" Galaxy Explorer\n",
    "## Part 1: Enriching Data with Keywords from TMDB\n",
    "\n",
    "Our goal is to create a rich \"fingerprint\" for each film, and that requires more than just genre and cast. We need to understand the film's plot and themes. In this step, we will use the TMDB API to fetch descriptive keywords and other useful metadata (like poster paths) for every Pre-Code film in our dataset.\n",
    "\n",
    "**Methodology:**\n",
    "1.  **Load Data:** Start with our `hollywood_df.pkl` file.\n",
    "2.  **Connect to TMDB:** Use the `tmdbsimple` library and our API key to connect to The Movie Database.\n",
    "3.  **Fetch Keywords:** For each movie (identified by its `tconst`), we will query the TMDB API to find its keywords.\n",
    "4.  **Handle Missing Data:** Some older films may not have entries or keywords. Our code must handle these cases gracefully.\n",
    "5.  **Save Enriched Data:** We will save the result to a new file, `hollywood_df_enriched.pkl`, to use in the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8518afd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TMDB API key loaded successfully from .env file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985ca8096fe343e7af5342ddada2726e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching Keywords from TMDB:   0%|          | 0/4514 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enrichment complete. Saved 4514 movies with keyword data.\n",
      "Sample of enriched data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>startYear</th>\n",
       "      <th>keywords</th>\n",
       "      <th>poster_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0017578</td>\n",
       "      <td>The Wrecker</td>\n",
       "      <td>1929</td>\n",
       "      <td></td>\n",
       "      <td>/oGCsBdjxDq7b4eTpTsjJrA6VayX.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0018362</td>\n",
       "      <td>The Scar of Shame</td>\n",
       "      <td>1929</td>\n",
       "      <td>marriage contract prison escape class differen...</td>\n",
       "      <td>/tosJ21bDxJzvg2JcTuKQMqWglvM.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0018588</td>\n",
       "      <td>Three Loves</td>\n",
       "      <td>1929</td>\n",
       "      <td>black and white silent film</td>\n",
       "      <td>/ncyxOfdoS0Rz9VWHxyx6HLyU5nB.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0018630</td>\n",
       "      <td>After the Verdict</td>\n",
       "      <td>1929</td>\n",
       "      <td>sports</td>\n",
       "      <td>/dOGxHjXBFp1D59hZLzBl9Gheg20.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0018685</td>\n",
       "      <td>The Bellamy Trial</td>\n",
       "      <td>1929</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tconst       primaryTitle  startYear  \\\n",
       "0  tt0017578        The Wrecker       1929   \n",
       "1  tt0018362  The Scar of Shame       1929   \n",
       "2  tt0018588        Three Loves       1929   \n",
       "3  tt0018630  After the Verdict       1929   \n",
       "4  tt0018685  The Bellamy Trial       1929   \n",
       "\n",
       "                                            keywords  \\\n",
       "0                                                      \n",
       "1  marriage contract prison escape class differen...   \n",
       "2                        black and white silent film   \n",
       "3                                             sports   \n",
       "4                                                      \n",
       "\n",
       "                        poster_path  \n",
       "0  /oGCsBdjxDq7b4eTpTsjJrA6VayX.jpg  \n",
       "1  /tosJ21bDxJzvg2JcTuKQMqWglvM.jpg  \n",
       "2  /ncyxOfdoS0Rz9VWHxyx6HLyU5nB.jpg  \n",
       "3  /dOGxHjXBFp1D59hZLzBl9Gheg20.jpg  \n",
       "4                              None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tmdbsimple as tmdb\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- 1. Load Environment Variables and Setup TMDB API ---\n",
    "# This will find the .env file in your project root and load the keys.\n",
    "load_dotenv()\n",
    "\n",
    "tmdb.API_KEY = os.getenv('TMDB_API_KEY')\n",
    "\n",
    "if tmdb.API_KEY:\n",
    "    print(\"TMDB API key loaded successfully from .env file.\")\n",
    "else:\n",
    "    print(\"Error: Could not load TMDB_API_KEY from .env file.\")\n",
    "    print(\"Please ensure your .env file exists in the project root and contains the key.\")\n",
    "\n",
    "# --- 2. Load our Hollywood DataFrame ---\n",
    "HOLLYWOOD_DF_PATH = \"../data/processed/hollywood_df.pkl\"\n",
    "hollywood_df = pd.read_pickle(HOLLYWOOD_DF_PATH)\n",
    "unique_movies_df = hollywood_df[['tconst', 'primaryTitle', 'startYear']].drop_duplicates(subset=['primaryTitle']).reset_index(drop=True)\n",
    "\n",
    "# --- 3. Function to Fetch Keywords for a tconst ---\n",
    "def get_keywords_from_tmdb(tconst):\n",
    "    if not tmdb.API_KEY:\n",
    "        return \"NO_API_KEY\", \"\"\n",
    "    try:\n",
    "        find = tmdb.Find(tconst)\n",
    "        response = find.info(external_source='imdb_id')\n",
    "        if not response['movie_results']:\n",
    "            return \"not_found\", \"\"\n",
    "        movie_id = response['movie_results'][0]['id']\n",
    "        movie = tmdb.Movies(movie_id)\n",
    "        keywords = movie.keywords()['keywords']\n",
    "        keyword_str = ' '.join([k['name'] for k in keywords])\n",
    "        poster_path = response['movie_results'][0].get('poster_path', '')\n",
    "        return keyword_str, poster_path\n",
    "    except Exception:\n",
    "        return \"api_error\", \"\"\n",
    "\n",
    "# --- 4. Loop Through Movies and Enrich Data ---\n",
    "if tmdb.API_KEY:\n",
    "    tqdm.pandas(desc=\"Fetching Keywords from TMDB\")\n",
    "    results = unique_movies_df['tconst'].progress_apply(get_keywords_from_tmdb)\n",
    "    unique_movies_df[['keywords', 'poster_path']] = pd.DataFrame(results.tolist(), index=unique_movies_df.index)\n",
    "\n",
    "    # --- 5. Save the Enriched Data ---\n",
    "    ENRICHED_DF_PATH = \"../data/processed/hollywood_df_enriched.pkl\"\n",
    "    unique_movies_df.to_pickle(ENRICHED_DF_PATH)\n",
    "\n",
    "    print(f\"\\nEnrichment complete. Saved {len(unique_movies_df)} movies with keyword data.\")\n",
    "    print(\"Sample of enriched data:\")\n",
    "    display(unique_movies_df.head())\n",
    "else:\n",
    "    print(\"\\nSkipping data enrichment because TMDB API key was not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30493868",
   "metadata": {},
   "source": [
    "## Part 2: Engineering the \"Movie DNA\" with AI\n",
    "\n",
    "With our enriched dataset, we can now perform the core machine learning task. We will use a pre-trained Sentence Transformer model, a powerful form of NLP AI, to read the plot keywords for each film and convert them into a high-dimensional vector, also known as an \"embedding.\" This vector is the film's unique \"DNA,\" capturing its thematic essence in a way the machine can understand.\n",
    "\n",
    "**Methodology:**\n",
    "1.  **Load Enriched Data:** We'll load the `hollywood_df_enriched.pkl` file we created in the previous step.\n",
    "2.  **Instantiate AI Model:** We will load a state-of-the-art model (`all-MiniLM-L6-v2`) from the `sentence-transformers` library. The first time this runs, it will download the model files (a few hundred MB).\n",
    "3.  **Generate Embeddings:** We will feed the `keywords` column into the model. The model will output a 384-dimension vector for each film.\n",
    "4.  **Save the DNA:** We will save these embeddings to a file so we don't have to re-calculate them every time. This is a crucial step in any ML pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# --- 1. Load the Enriched Data ---\n",
    "ENRICHED_DF_PATH = \"../data/processed/hollywood_df_enriched.pkl\"\n",
    "enriched_df = pd.read_pickle(ENRICHED_DF_PATH)\n",
    "\n",
    "print(\"Enriched movie data loaded successfully.\")\n",
    "\n",
    "# --- 2. Prepare the Text Data ---\n",
    "# Fill any missing keywords with an empty string so the model can process them.\n",
    "enriched_df['keywords'] = enriched_df['keywords'].fillna('')\n",
    "\n",
    "# Create a list of all keyword strings to feed to the model\n",
    "corpus = enriched_df['keywords'].tolist()\n",
    "\n",
    "# --- 3. Instantiate and Use the Transformer Model ---\n",
    "# This model is small but powerful, great for our use case.\n",
    "# The model will be downloaded from the internet the first time you run this.\n",
    "print(\"Loading Sentence Transformer model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "# --- 4. Generate the Embeddings (The \"Movie DNA\") ---\n",
    "# The model.encode() function will process the text and output the vectors.\n",
    "# We wrap it in tqdm to see a progress bar.\n",
    "print(\"Generating movie DNA embeddings... (This may take a minute)\")\n",
    "movie_dna_embeddings = model.encode(corpus, show_progress_bar=True)\n",
    "\n",
    "# --- 5. Save the Embeddings ---\n",
    "EMBEDDINGS_PATH = \"../data/processed/movie_dna_embeddings.npy\"\n",
    "np.save(EMBEDDINGS_PATH, movie_dna_embeddings)\n",
    "\n",
    "print(\"\\nMovie DNA creation complete!\")\n",
    "print(f\"Shape of our DNA matrix: {movie_dna_embeddings.shape}\")\n",
    "print(f\"(This means {movie_dna_embeddings.shape[0]} movies, each with a {movie_dna_embeddings.shape[1]}-dimension DNA vector)\")\n",
    "print(f\"Embeddings saved to: {EMBEDDINGS_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
